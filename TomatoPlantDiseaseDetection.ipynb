{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a58decff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications import ResNet152V2\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "778fd953",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path ='/Users/arghaauddy/Downloads/tomato/train'\n",
    "val_path='/Users/arghaauddy/Downloads/tomato/val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e20a1b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10000 images belonging to 10 classes.\n",
      "Found 1000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Apply ImageDataGenerator functionality to Trainset and Test set\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=(256, 256),\n",
    "    batch_size=80,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_path,\n",
    "    target_size=(256, 256),\n",
    "    batch_size=80,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "484e6618",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = ResNet152V2(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
    "\n",
    "# Adding Dense Layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1000, activation='relu')(x)\n",
    "predictions = Dense(10, activation='softmax')(x)\n",
    "\n",
    "# The final model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Configure the Learning Process\n",
    "for layers in base_model.layers[:140]:\n",
    "    layers.trainable=False\n",
    "for layers in base_model.layers[140:]:\n",
    "    layers.trainable=True\n",
    "\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b6dace3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arghaauddy/anaconda3/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4341s\u001b[0m 35s/step - accuracy: 0.5093 - loss: 1.5584 - val_accuracy: 0.8470 - val_loss: 0.4740\n",
      "Epoch 2/2\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5876s\u001b[0m 47s/step - accuracy: 0.9186 - loss: 0.2640 - val_accuracy: 0.9320 - val_loss: 0.1846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=2\n",
    ")\n",
    "\n",
    "# Save the Model\n",
    "model.save('tomato_disease_detector.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0788fca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "The disease detected is: Tomato___Tomato_Yellow_Leaf_Curl_Virus\n"
     ]
    }
   ],
   "source": [
    "# Import additional libraries for handling image input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "# Load the trained model\n",
    "model = tf.keras.models.load_model('tomato_disease_detector.h5')\n",
    "\n",
    "# Define a function to preprocess the input image and make a prediction\n",
    "def predict_disease(img_path):\n",
    "    img = image.load_img(img_path, target_size=(256, 256))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array /= 255.0\n",
    "\n",
    "    prediction = model.predict(img_array)\n",
    "    class_indices = {v: k for k, v in train_generator.class_indices.items()}\n",
    "    predicted_class = np.argmax(prediction, axis=1)[0]\n",
    "    disease_name = class_indices[predicted_class]\n",
    "\n",
    "    return disease_name\n",
    "\n",
    "# Test the function\n",
    "img_path = '/Users/arghaauddy/Downloads/tomato/val/Tomato___Tomato_Yellow_Leaf_Curl_Virus/1af87bdf-0bd0-4146-93e5-cc5f97d98b05___UF.GRC_YLCV_Lab 01968.JPG' # Replace with the path to your test image\n",
    "disease_name = predict_disease(img_path)\n",
    "print(f\"The disease detected is: {disease_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8090876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/arghaauddy'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f36a69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
